This is a lightweight character level [LSTM](https://en.wikipedia.org/wiki/Long_short-term_memory) Recurrent Neural Network. The source text for this model is the American King James Version of the Bible, which can be found on [OpenBible](https://openbible.com/textfiles/akjv.txt).

Data processing, model implementation, and model training are done in Python using Pandas and PyTorch. Matplotlib was used for initial data exploration and visualization of training metrics as part of model fine-tuning. After several development iterations, the final computation graph was exported to [ONNX](https://docs.pytorch.org/docs/stable/onnx.html) format, allowing the model to be served to the client for in-browser inference via the [`onnxruntime-web`](https://onnxruntime.ai/docs/) Javascript library.

The entire deployed model package (consisting of the `.onnx` model file and auxiliary assets, the ONNX Runtime WebAssembly module, and the Javascript sampling logic), has a minimal footprint of only 25 MB. Load time is typically `<1s` for desktop<a href="/bible-rnn/desktop_performance.html" class="cite">[1]</a> and `~3s` on mobile.<a href="/bible-rnn/mobile_performance.html" class="cite">[2]</a>

For implementation details, including the full PyTorch source code and related language modeling projects, feel free to visit my [GitHub repository](https://github.com/ruitaiS/language_models).