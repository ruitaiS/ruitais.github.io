### Intro

This is a lightweight character level [LSTM](https://en.wikipedia.org/wiki/Long_short-term_memory) Recurrent Neural Network trained on the Bible as a text corpus. Data processing, model implementation, and model training are done in Python using Pandas and PyTorch. Matplotlib was used for initial data exploration and visualization of training metrics as part of model fine-tuning. After several development iterations, the finalized computation graph is exported to [ONNX](https://docs.pytorch.org/docs/stable/onnx.html) format, allowing it to be served to the client for in-browser inference via the [`onnxruntime-web`](https://onnxruntime.ai/docs/) Javascript library.

The final model package (comprising the `.onnx` model file, model vocabulary and metadata assets, and the embedded JS code needed to sample from the model) comes in at under `22mb`. Load time is typically `<1s` for desktop <a href="/bible-rnn/desktop_performance.html" class="cite">[1]</a> and `~3s` on mobile. <a href="/bible-rnn/mobile_performance.html" class="cite">[2]</a>

You can find the PyTorch code for this model, as well as some of my other language modelling projects, in this [GitHub Repository](https://github.com/ruitaiS/language_models).